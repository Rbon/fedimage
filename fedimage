#!/usr/bin/env python


"""
Checks your mastodon/misskey follows, and downloads any media posted recently.
"""


import os
import re
import argparse
import sqlite3
import time
import requests


DEBUG = False


class Fedimage:
    """The main functions for this script."""


    def __init__(self):
        self.script_path = os.path.dirname(os.path.realpath(__file__))
        self.conn = sqlite3.connect("fedimage.db")
        self.dl_dir = self.script_path + "/downloads"
        self.feed_dir = self.script_path + "/feeds"
        self.feeds_file = self.script_path + "/feeds.txt"
        self.cli_args = self._get_args()
        self.verbosity = self.cli_args.verbosity
        self.dl_list = []


    def _get_args(self):
        """Get the command-line arguments, and return an argparse namespace."""
        parser = argparse.ArgumentParser()
        parser.add_argument(
            'file',
            nargs='?',
            help="A csv file containing account names.")
        parser.add_argument(
            '-v', '--verbosity',
            type=int,
            default=1,
            help="Specify how verbose fedimage is. By default, this is 1."
        )
        args = parser.parse_args()
        return args


    def main(self):
        """Main function."""
        start_time = time.time()
        self.init_dirs()
        args = self.cli_args
        if args.file:
            self.generate_feeds_file(args)
        self.sync_feeds()
        self.conn.close()
        if self.verbosity >= 1:
            total_time = round(time.time() - start_time, 2)
            print(
                f"DOWNLOADED {len(self.dl_list)} FILES",
                f"IN {total_time} SECONDS")


    def generate_feeds_file(self, args):
        """Generate feeds.txt from the kind of csv mastondon lets you export."""
        if self.verbosity >= 1:
            print(f"GENERATING FEEDS FILE FROM {args.file}")
        with open(args.file, encoding="utf-8") as users_filename:
            next(users_filename) # skip the header line
            output = []
            for username in users_filename:
                username = username.strip()
                matches = re.search(r"(.*)@(.*),.*,.*,", username)
                output.append(
                    f"https://{matches.group(2)}/@{matches.group(1)}.rss")
        with open(self.feeds_file, 'w', encoding="utf-8") as feeds_file:
            feeds_file.write("\n".join(output))


    def sync_feeds(self):
        """Read feeds.txt and sync each feed, one by one."""
        with open(self.feeds_file, encoding="utf-8") as feeds_filename:
            for feed_url in feeds_filename:
                feed_url = feed_url.strip()
                matches = re.search(r".*:\/\/(.*)\/@(.*)\.rss", feed_url)
                filename = f"{matches.group(2)}@{matches.group(1)}.rss"

                self.download_rss_file(feed_url, self.feed_dir + "/" + filename)
                self.parse_feed(self.feed_dir + "/" + filename)
                if self.verbosity >= 1:
                    print(80*"-")


    def init_dirs(self):
        """Create the needed directories, if they don't already exist."""
        for directory in [self.dl_dir, self.feed_dir]:
            if not os.path.exists(directory):
                os.makedirs(directory)


    def download_rss_file(self, feed_url, filename):
        """Fetch a feed from a URL, and save it as the specified filename."""
        if DEBUG:
            if self.verbosity >= 1:
                print(f"(FAKE) FETCHING FEED FROM {feed_url}")
            return
        if self.verbosity >= 1:
            print(f"FETCHING FEED FROM {feed_url}")
        feed_file = requests.get(feed_url, timeout=30).content
        with open(filename, 'wb') as handler:
            handler.write(feed_file)


    def parse_feed(self, feed_filename):
        """Parse an RSS feed file, and download any media."""
        creator = os.path.basename(os.path.splitext(feed_filename)[0])
        if self.verbosity >= 2:
            print(f"CHECKING FOR MEDIA FROM {creator}")

        cursor = self.conn.cursor()
        cursor.execute(f"""
            CREATE TABLE if not exists '{creator}' (mediaURL text)
            """)
        self.conn.commit()

        with open(feed_filename, encoding="utf-8") as feed:
            got_item = False
            text_item = {}
            for line in feed:
                line = line.strip()
                # print(line)

                if line == "<item>":
                    got_item = True
                    continue

                if got_item:
                    if line == "</item>":
                        if "mediaURL" in text_item:
                            item = Item(
                                creator = creator,
                                source = text_item["link"],
                                media_url = text_item["mediaURL"],
                                conn = self.conn,
                                dl_dir = self.dl_dir,
                                verbosity=self.verbosity)
                            url = item.download_media()
                            if url is not None:
                                self.dl_list.append(url)
                            # print()
                        got_item = False
                        text_item = {}
                        continue

                    text_item["creator"] = creator
                    cdata_match = re.search(
                        r"<(.*)><!\[CDATA\[(.*)\]\]><\/.*>",
                        line)
                    normal_match = re.search(r"<(.*)>(.*)<\/.*>", line)
                    media_match = re.search(
                        r'<enclosure url="(.*)" length=".*" type=".*"/>',
                        line)
                    mastodon_media_match = re.search(
                        (
                            r'^<media:content url="(.*)" '
                            r'type=".*" fileSize=".*" medium=".*">$'),
                        line)

                    if cdata_match:
                        text_item[cdata_match.group(1)] = cdata_match.group(2)
                    elif normal_match:
                        text_item[normal_match.group(1)] = normal_match.group(2)
                    elif media_match:
                        text_item["mediaURL"] = media_match.group(1)
                    elif mastodon_media_match:
                        text_item["mediaURL"] = mastodon_media_match.group(1)


class Item:
    """Represents each media items found in the RSS fields."""


    def __init__(self, creator, source, media_url, conn, dl_dir, verbosity):
        self.creator = creator
        self.source = source
        self.media_url = media_url
        self._filename = None
        self._already_downloaded = None
        self.conn = conn
        self.dl_dir = dl_dir
        self.verbosity = verbosity


    @property
    def filename(self):
        """The basename of the media file on the server."""
        if self._filename:
            return self._filename

        self._filename = self.dl_dir + "/" + re.search(
            r".*\/([^\/].*)", self.media_url).group(1)
        return self._filename


    @property
    def already_downloaded(self):
        """Returns a boolean representing if the item has been downloaded."""
        cursor = self.conn.cursor()
        cursor.execute(f"""
            SELECT * FROM '{self.creator}'
            WHERE mediaURL = '{self.media_url}'
            """)
        data=cursor.fetchone()

        if data is None:
            self._already_downloaded = False
        else:
            self._already_downloaded = True

        return self._already_downloaded


    def add_to_database(self):
        """Add to the database a record of this item."""
        cursor = self.conn.cursor()
        cursor.execute(f"""
            INSERT INTO '{self.creator}
            'VALUES ('{self.media_url}')
            """)
        self.conn.commit()


    def download_media(self):
        """
        Download this media item, and save it to the downloads directory.
        
        Returns the URL of anything downloaded, None if nothing was downloaded.
        """
        if DEBUG:
            if self.verbosity >= 1:
                print(f"(FAKE) DOWNLOADING {self.media_url}")
            if self.verbosity >= 2:
                print(f"(FAKE) SAVING AS {self.filename}")
            self.generate_tag_file()
            return self.media_url

        if self.verbosity >= 1:
            print(f"DOWNLOADING {self.media_url}")
        if self.already_downloaded:
            if self.verbosity >= 1:
                print("Already downloaded.")
            return
        if self.verbosity >= 2:
            print(f"SAVING AS {self.filename}")
        img_data = requests.get(self.media_url, timeout=30).content
        with open(self.filename, 'wb') as handler:
            handler.write(img_data)
        print(f"SAVING AS {self.filename}")
        self.generate_tag_file()
        self.add_to_database()
        return self.media_url


    def generate_tag_file(self):
        """Write the accompanying tag text file for this item."""
        tag_filename = self.filename + ".txt"

        if self.verbosity >= 2:
            print(f"WRITING TAGS TO {tag_filename}")
        with open(tag_filename, "w", encoding="utf-8") as tag_file:
            tag_file.write(
                f"creator:{self.creator}\nsource:{self.source}")


if __name__ == "__main__":
    Fedimage().main()
