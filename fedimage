#!/usr/bin/env python


"""
Fedimage

Download media files from your mastodon/misskey follows.

MIT License

Copyright (c) 2023 Robin Bisho

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

"""


import os
import re
import argparse
import sqlite3
import time
import tempfile
import requests


DEBUG = False


class Fedimage:
    """The main functions for this script."""


    def __init__(self):
        self.script_path = os.path.dirname(os.path.realpath(__file__))
        self.cli_args = self._get_args()
        self.conn = sqlite3.connect("fedimage.db")
        self.feeds_file = self.cli_args.feeds_file
        self.dl_list = []


    def _get_args(self):
        """Get the command-line arguments, and return an argparse namespace."""
        parser = argparse.ArgumentParser(
            prog='fedimage',
            description="""
                Download media files from your mastodon/misskey follows.
            """)
        parser.add_argument(
            'feeds_file',
            help="""
                A text file containing a newline-separated list RSS feed
                URLs.
            """)
        parser.add_argument(
            '-v', '--verbosity',
            choices=[0, 1, 2],
            type=int,
            default=1,
            help="""
                Specify how verbose fedimage is. By default, this is 1. A
                verbosity of 0 will completely silence fedimage.
            """)
        parser.add_argument(
            '-m', '--media-dir',
            default=self.script_path + "/media",
            metavar="DIRECTORY",
            help="""
                The directory to save downloaded media. By default, fedimage
                will create a 'media' directory wherever it is located, and
                save any media there.
            """)
        parser.add_argument(
            '-d', '--database',
            default=self.script_path + "fedimage.db",
            metavar="DIRECTORY",
            help="""
                The path for the database of downloaded media. Fedimage uses
                this to ensure that files are only downloaded once. By default,
                fedimage will create a database in the directory where fedimage
                itself is located.
            """)
        parser.add_argument(
            '-c', '--csv-file',
            metavar="FILE",
            help="""
                Read follows from a CSV file exported from mastodon. Fedimage
                will then write these exports to whatever you specify as
                feeds_file, before downloading media as usual.
            """)
        parser.add_argument(
            '-r', '--rss-dir',
            default=None,
            metavar="DIRECTORY",
            help="""
                The directory to save downloaded RSS feeds. By default, fedimage
                will create a temporary directory to save feeds.
            """)
        args = parser.parse_args()
        return args


    def main(self):
        """Main function."""
        start_time = time.time()
        self.init_dirs()
        args = self.cli_args
        if args.csv_file:
            self.generate_feeds_file(args.csv_file)
        self.sync_feeds()
        self.conn.close()
        if self.cli_args.verbosity >= 1:
            total_time = round(time.time() - start_time, 2)
            print(
                f"DOWNLOADED {len(self.dl_list)} FILES",
                f"IN {total_time} SECONDS")


    def generate_feeds_file(self, csv_file):
        """Generate feeds.txt from the kind of csv mastondon lets you export."""
        if self.cli_args.verbosity >= 1:
            print(f"GENERATING FEEDS FILE FROM {csv_file}")
        with open(csv_file, encoding="utf-8") as users_filename:
            next(users_filename) # skip the header line
            output = []
            for username in users_filename:
                username = username.strip()
                matches = re.search(r"(.*)@(.*),.*,.*,", username)
                output.append(
                    f"https://{matches.group(2)}/@{matches.group(1)}.rss")
        with open(self.feeds_file, 'w', encoding="utf-8") as feeds_file:
            feeds_file.write("\n".join(output))


    def sync_feeds(self):
        """Choose the appropriate directory, and sync feeds."""
        if self.cli_args.rss_dir is None:
            with tempfile.TemporaryDirectory() as tmpdirname:
                self._sync_feeds(tmpdirname)
        else:
            self._sync_feeds(self.cli_args.rss_dir)


    def _sync_feeds(self, dirname):
        """Read feeds.txt and sync each feed, one by one."""
        with open(self.feeds_file, encoding="utf-8") as feeds_filename:
            for feed_url in feeds_filename:
                feed_url = feed_url.strip()
                matches = re.search(r".*:\/\/(.*)\/@(.*)\.rss", feed_url)
                filename = f"{matches.group(2)}@{matches.group(1)}.rss"
                self.download_rss_file(
                    feed_url,
                    dirname + "/" + filename)
                self.parse_feed(dirname + "/" + filename)
                if self.cli_args.verbosity >= 1:
                    print(80*"-")


    def init_dirs(self):
        """Create the needed directories, if they don't already exist."""
        for directory in [self.cli_args.media_dir]:
            if not os.path.exists(directory):
                os.makedirs(directory)


    def download_rss_file(self, feed_url, filename):
        """Fetch a feed from a URL, and save it as the specified filename."""
        if DEBUG:
            if self.cli_args.verbosity >= 1:
                print(f"(FAKE) FETCHING FEED FROM {feed_url}")
            return
        if self.cli_args.verbosity >= 1:
            print(f"FETCHING FEED FROM {feed_url}")
        feed_file = requests.get(feed_url, timeout=30).content
        with open(filename, 'wb') as handler:
            handler.write(feed_file)


    def parse_feed(self, feed_filename):
        """Parse an RSS feed file, and download any media."""
        creator = os.path.basename(os.path.splitext(feed_filename)[0])
        if self.cli_args.verbosity >= 2:
            print(f"CHECKING FOR MEDIA FROM {creator}")

        cursor = self.conn.cursor()
        cursor.execute(f"""
            CREATE TABLE if not exists '{creator}' (mediaURL text)
            """)
        self.conn.commit()

        with open(feed_filename, encoding="utf-8") as feed:
            got_item = False
            text_item = {}
            for line in feed:
                line = line.strip()
                # print(line)

                if line == "<item>":
                    got_item = True
                    continue

                if got_item:
                    if line == "</item>":
                        if "mediaURL" in text_item:
                            item = Item(
                                creator = creator,
                                source = text_item["link"],
                                media_url = text_item["mediaURL"],
                                conn = self.conn,
                                dl_dir = self.cli_args.media_dir,
                                verbosity=self.cli_args.verbosity)
                            url = item.download_media()
                            if url is not None:
                                self.dl_list.append(url)
                            # print()
                        got_item = False
                        text_item = {}
                        continue

                    text_item["creator"] = creator
                    cdata_match = re.search(
                        r"<(.*)><!\[CDATA\[(.*)\]\]><\/.*>",
                        line)
                    normal_match = re.search(r"<(.*)>(.*)<\/.*>", line)
                    media_match = re.search(
                        r'<enclosure url="(.*)" length=".*" type=".*"/>',
                        line)
                    mastodon_media_match = re.search(
                        (
                            r'^<media:content url="(.*)" '
                            r'type=".*" fileSize=".*" medium=".*">$'),
                        line)

                    if cdata_match:
                        text_item[cdata_match.group(1)] = cdata_match.group(2)
                    elif normal_match:
                        text_item[normal_match.group(1)] = normal_match.group(2)
                    elif media_match:
                        text_item["mediaURL"] = media_match.group(1)
                    elif mastodon_media_match:
                        text_item["mediaURL"] = mastodon_media_match.group(1)


class Item:
    """Represents each media items found in the RSS fields."""


    def __init__(self, creator, source, media_url, conn, dl_dir, verbosity):
        self.creator = creator
        self.source = source
        self.media_url = media_url
        self._filename = None
        self._already_downloaded = None
        self.conn = conn
        self.dl_dir = dl_dir
        self.verbosity = verbosity


    @property
    def filename(self):
        """The basename of the media file on the server."""
        if self._filename:
            return self._filename

        self._filename = self.dl_dir + "/" + re.search(
            r".*\/([^\/].*)", self.media_url).group(1)
        return self._filename


    @property
    def already_downloaded(self):
        """Returns a boolean representing if the item has been downloaded."""
        cursor = self.conn.cursor()
        cursor.execute(f"""
            SELECT * FROM '{self.creator}'
            WHERE mediaURL = '{self.media_url}'
            """)
        data=cursor.fetchone()

        if data is None:
            self._already_downloaded = False
        else:
            self._already_downloaded = True

        return self._already_downloaded


    def add_to_database(self):
        """Add to the database a record of this item."""
        cursor = self.conn.cursor()
        cursor.execute(f"""
            INSERT INTO '{self.creator}'
            VALUES ('{self.media_url}')
            """)
        self.conn.commit()


    def download_media(self):
        """
        Download this media item, and save it to the downloads directory.
        
        Returns the URL of anything downloaded, None if nothing was downloaded.
        """
        if DEBUG:
            if self.verbosity >= 1:
                print(f"(FAKE) DOWNLOADING {self.media_url}")
            if self.verbosity >= 2:
                print(f"(FAKE) SAVING AS {self.filename}")
            self.generate_tag_file()
            return self.media_url

        if self.already_downloaded:
            if self.verbosity >= 2:
                print(f"DOWNLOADING {self.media_url}")
                print("Already downloaded.")
            return None

        if self.verbosity >= 1:
            print(f"DOWNLOADING {self.media_url}")
        img_data = requests.get(self.media_url, timeout=30).content

        if self.verbosity >= 2:
            print(f"SAVING AS {self.filename}")
        with open(self.filename, 'wb') as handler:
            handler.write(img_data)

        self.generate_tag_file()
        self.add_to_database()
        return self.media_url


    def generate_tag_file(self):
        """Write the accompanying tag text file for this item."""
        tag_filename = self.filename + ".txt"

        if self.verbosity >= 2:
            print(f"WRITING TAGS TO {tag_filename}")
        with open(tag_filename, "w", encoding="utf-8") as tag_file:
            tag_file.write(
                f"creator:{self.creator}\nsource:{self.source}")


if __name__ == "__main__":
    Fedimage().main()
